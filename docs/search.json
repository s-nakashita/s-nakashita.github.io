[
  {
    "objectID": "pyesa/index.html",
    "href": "pyesa/index.html",
    "title": "Ensemble sensitivity analysis with Python",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ensemble sensitivity analysis with Python",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "L63_PLS.html",
    "href": "L63_PLS.html",
    "title": "Lorenz-63",
    "section": "",
    "text": "Code\nimport numpy as np\nCode\nclass L63():\n    def __init__(self):\n        self.p = 10.0 # prandtl number\n        self.r = 32.0 # rayleigh number\n        self.b = 8.0/3.0 # aspect ratio\n        self.dt = 0.01\n\n    def __call__(self,w):\n        x, y, z = w \n        dw = np.zeros_like(w)\n        dw[0] = -self.p * x + self.p * y\n        dw[1] = -x * z      + self.r * x - y\n        dw[2] = x * y       - self.b * z\n        return w + dw * self.dt\n    \n    def tlm(self,wb,wt):\n        xb, yb, zb = wb\n        xt, yt, zt = wt \n        dw = np.zeros_like(wt)\n        dw[0] = -self.p * xt     + self.p * yt\n        dw[1] = (self.r - zb)*xt - yt          - xb*zt\n        dw[2] = yb*xt            + xb*yt       - self.b * zt\n        return wt + dw * self.dt\n    \n    def adj(self,wb,wt):\n        xb, yb, zb = wb\n        xt, yt, zt = wt \n        dw = np.zeros_like(wt)\n        dw[0] = -self.p * xt + (self.r - zb)*yt + yb*zt\n        dw[1] =  self.p * xt - yt               + xb*zt\n        dw[2] =              - xb*yt            - self.b * zt\n        return wt + dw * self.dt\nCode\nimport matplotlib.pyplot as plt \n\nmodel = L63()\nnstep = 500\n\nw1 = np.zeros((nstep+1,3))\nw2 = np.zeros((nstep+1,3))\nw1[0,:] = 1.0,3.0,5.0\nw2[0,:] = 1.1,3.3,5.5\nfor i in range(nstep):\n    w1[i+1,] = model(w1[i])\n    w2[i+1,] = model(w2[i])\n\nfig = plt.figure(figsize=[8,8])\nax = fig.add_subplot(projection=\"3d\")\nax.plot(*w1.transpose())\nax.plot(*w2.transpose())\nplt.show()"
  },
  {
    "objectID": "L63_PLS.html#tlm-and-adj-check",
    "href": "L63_PLS.html#tlm-and-adj-check",
    "title": "Lorenz-63",
    "section": "TLM and ADJ check",
    "text": "TLM and ADJ check\n\n\nCode\nmodel = L63()\n# TLM check\nw0 = np.random.randn(3)\ndw0 = np.random.randn(3)*0.1\nalp = 1.0e-5\nwp = model(w0+alp*dw0)\nwb = model(w0)\ndw = model.tlm(w0,dw0)\nratio = np.sqrt(np.dot((wp-wb),(wp-wb)))/alp/np.sqrt(np.dot(dw,dw))\nprint(f\"|M(x+a*dx)-M(x)|/|a*TLM*dx|={ratio}\")\n# ADJ check\nMtMw = model.adj(w0,dw)\nprint(f\"(Mx)^T(Mx)-x^TM^TMx={np.dot(dw,dw)-np.dot(dw0,MtMw)}\")\n\n\n|M(x+a*dx)-M(x)|/|a*TLM*dx|=1.0000000008559033\n(Mx)^T(Mx)-x^TM^TMx=0.0"
  },
  {
    "objectID": "L63_PLS.html#singular-vector",
    "href": "L63_PLS.html#singular-vector",
    "title": "Lorenz-63",
    "section": "Singular vector",
    "text": "Singular vector\n\n\nCode\n## base field\nwb = np.array([1.0,3.0,5.0])\nnstep = 100\nfor i in range(nstep):\n    wb = model(wb)\n\n\n\nLanczos method\n\n\nCode\n# initialize\nalpha=1.0e-5\ndw = np.random.randn(3)\ndw = dw * alpha / np.sqrt(np.dot(dw,dw))\nniter=0\nwhile(True):\n    dwp = dw.copy()\n    # forward integration\n    dw = model.tlm(wb,dw)\n    # backward integration\n    dw = model.adj(wb,dw)\n    # rescaling\n    dw = dw * alpha / np.sqrt(np.dot(dw,dw))\n    # convergence evaluation\n    diff = np.sqrt(np.dot((dw-dwp),(dw-dwp)))\n    niter+=1\n    print(f\"iter:{niter}, diff={diff:.3e}\")\n    if diff/alpha&lt;1.0e-6: break\nprint(dw/alpha)\n\n\niter:1, diff=2.450e-06\niter:2, diff=2.557e-06\niter:3, diff=2.135e-06\niter:4, diff=1.540e-06\niter:5, diff=1.058e-06\niter:6, diff=7.428e-07\niter:7, diff=5.475e-07\niter:8, diff=4.226e-07\niter:9, diff=3.365e-07\niter:10, diff=2.725e-07\niter:11, diff=2.225e-07\niter:12, diff=1.822e-07\niter:13, diff=1.495e-07\niter:14, diff=1.226e-07\niter:15, diff=1.006e-07\niter:16, diff=8.254e-08\niter:17, diff=6.770e-08\niter:18, diff=5.552e-08\niter:19, diff=4.553e-08\niter:20, diff=3.733e-08\niter:21, diff=3.061e-08\niter:22, diff=2.510e-08\niter:23, diff=2.058e-08\niter:24, diff=1.687e-08\niter:25, diff=1.383e-08\niter:26, diff=1.134e-08\niter:27, diff=9.296e-09\niter:28, diff=7.621e-09\niter:29, diff=6.248e-09\niter:30, diff=5.123e-09\niter:31, diff=4.200e-09\niter:32, diff=3.443e-09\niter:33, diff=2.823e-09\niter:34, diff=2.314e-09\niter:35, diff=1.897e-09\niter:36, diff=1.555e-09\niter:37, diff=1.275e-09\niter:38, diff=1.045e-09\niter:39, diff=8.571e-10\niter:40, diff=7.027e-10\niter:41, diff=5.761e-10\niter:42, diff=4.723e-10\niter:43, diff=3.872e-10\niter:44, diff=3.174e-10\niter:45, diff=2.602e-10\niter:46, diff=2.134e-10\niter:47, diff=1.749e-10\niter:48, diff=1.434e-10\niter:49, diff=1.176e-10\niter:50, diff=9.638e-11\niter:51, diff=7.902e-11\niter:52, diff=6.478e-11\niter:53, diff=5.311e-11\niter:54, diff=4.354e-11\niter:55, diff=3.570e-11\niter:56, diff=2.927e-11\niter:57, diff=2.399e-11\niter:58, diff=1.967e-11\niter:59, diff=1.613e-11\niter:60, diff=1.322e-11\niter:61, diff=1.084e-11\niter:62, diff=8.886e-12\n[-0.59253212 -0.76624265  0.24855156]"
  },
  {
    "objectID": "EnASA_L96.html",
    "href": "EnASA_L96.html",
    "title": "Comparison of adjoint sensitivity analysis and ensemble adjoint sensitivity analysis using Lorenz-96 model",
    "section": "",
    "text": "Code\nimport os\nimport sys\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import Normalize\nfrom numpy.random import default_rng"
  },
  {
    "objectID": "EnASA_L96.html#basic-state",
    "href": "EnASA_L96.html#basic-state",
    "title": "Comparison of adjoint sensitivity analysis and ensemble adjoint sensitivity analysis using Lorenz-96 model",
    "section": "basic state",
    "text": "basic state\n\n\nCode\n# initialize random seed\nrng = default_rng(509)\n# spinup\nx = rng.normal(0.0,size=nx,scale=1.0)\nnstep = 500\nfor i in range(nstep):\n    x = model(x)\n\nvtmax = 120 # hours\nvt = 24 # hours\nit = 21 # target point\nt = [0]\nxb = [x]\nfor i in range(vtmax):\n    x = model(x)\n    t.append(i)\n    xb.append(x)\nplt.plot(xb[0],label='initial')\nplt.plot(xb[vt],label='valid')\nplt.plot([it],xb[vt][it],marker='o',c='r')\nplt.grid()\nplt.legend()\nplt.show()\n\nmp = plt.pcolormesh(np.arange(nx),t,np.array(xb),\\\n    shading='auto',norm=Normalize(-10,10),cmap='coolwarm')\nif vt &lt; vtmax:\n    plt.hlines([vt],0,nx-1,colors='k',ls='dashed')\nplt.colorbar(mp)\nplt.show()"
  },
  {
    "objectID": "EnASA_L96.html#forecast-metric",
    "href": "EnASA_L96.html#forecast-metric",
    "title": "Comparison of adjoint sensitivity analysis and ensemble adjoint sensitivity analysis using Lorenz-96 model",
    "section": "Forecast metric",
    "text": "Forecast metric\n\\[\nJ(\\mathbf{x}_T)=\\frac{1}{2}x_T(i_t)^2\n\\] \\[\n\\frac{\\partial J}{\\partial \\mathbf{x}_T}=\\left\\{\n\\begin{matrix}\nx_T(i_t) & i=i_t\\\\\n0 & i\\ne i_t\n\\end{matrix}\\right.\n\\]\n\n\nCode\ndef calc_j(x):\n    return 0.5*x[it]*x[it]\n\ndef calc_jac(x):\n    dJdx = np.zeros_like(x)\n    dJdx[it] = x[it]\n    return dJdx"
  },
  {
    "objectID": "EnASA_L96.html#minimum-norm-solution",
    "href": "EnASA_L96.html#minimum-norm-solution",
    "title": "Comparison of adjoint sensitivity analysis and ensemble adjoint sensitivity analysis using Lorenz-96 model",
    "section": "minimum norm solution",
    "text": "minimum norm solution\nEnomoto et al. (2015); Hacker and Lei (2015)\n\\[\n\\left(\\frac{\\partial J_\\mathrm{e}}{\\partial \\mathbf{x}_0}\\right)_\\mathrm{minnorm}=\\mathbf{X}_0(\\mathbf{X}_0^\\mathrm{T}\\mathbf{X}_0)^\\dagger\\mathbf{J}_\\mathrm{e}\n\\tag{6}\\]\n\n\nCode\nsolver='minnorm'\ndJedx0, dxeopt=enasa(solver=solver)\ndJdx0_dict[solver] = dJedx0\ndxopt_dict[solver] = dxeopt\nJeest_dict[solver] = enasa.estimate()\nres_nl, res_tl = check_djdx(dJedx0,dxeopt,vt,title=solver)\nresnl_dict[solver] = res_nl \nrestl_dict[solver] = res_tl"
  },
  {
    "objectID": "EnASA_L96.html#minimum-variance-solution",
    "href": "EnASA_L96.html#minimum-variance-solution",
    "title": "Comparison of adjoint sensitivity analysis and ensemble adjoint sensitivity analysis using Lorenz-96 model",
    "section": "minimum variance solution",
    "text": "minimum variance solution\n\\[\n\\left(\\frac{\\partial J_\\mathrm{e}}{\\partial \\mathbf{x}_0}\\right)_\\mathrm{minvar}=(\\mathbf{X}_0\\mathbf{X}_0^\\mathrm{T})^{-1}\\mathbf{X}_0\\mathbf{J}_\\mathrm{e},\n\\tag{7}\\] which cannot be determined if \\(\\mathbf{X}_0\\mathbf{X}_0^\\mathrm{T}\\) is singular (which is true for most cases).\n\ndiagonal approximation (Ancell and Hakim 2007) \\[\n\\left(\\frac{\\partial J_\\mathrm{e}}{\\partial \\mathbf{x}_0}\\right)_\\mathrm{diag}=(\\mathrm{diag}[\\mathbf{X}_0\\mathbf{X}_0^\\mathrm{T}])^{-1}\\mathbf{X}_0\\mathbf{J}_\\mathrm{e}\n\\tag{8}\\]\n\n\n\nCode\nsolver='diag'\ndJedx0, dxeopt=enasa(solver=solver)\ndJdx0_dict[solver] = dJedx0\ndxopt_dict[solver] = dxeopt\nJeest_dict[solver] = enasa.estimate()\nres_nl, res_tl = check_djdx(dJedx0,dxeopt,vt,title=solver)\nresnl_dict[solver] = res_nl \nrestl_dict[solver] = res_tl\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npseudoinverse \\[\n\\left(\\frac{\\partial J_\\mathrm{e}}{\\partial \\mathbf{x}_0}\\right)_\\mathrm{psd}=(\\mathbf{X}_0\\mathbf{X}_0^\\mathrm{T})^\\dagger\\mathbf{X}_0\\mathbf{J}_\\mathrm{e}\n\\tag{9}\\] This is equivalent to the minimum norm solution (Eq. 6).\n\n\n\nprincipal component regression (PCR) \\[\n\\frac{1}{K-1}\\mathbf{X}_0\\mathbf{X}_0^\\mathrm{T}=\\mathbf{P}_R\\boldsymbol{\\Lambda}\\mathbf{P}_R^\\mathrm{T}\n\\] \\[\n\\mathbf{T}_R = \\mathbf{P}_R^\\mathrm{T}\\mathbf{X}_0\n\\] \\[\n\\left(\\frac{\\partial J_\\mathrm{e}}{\\partial \\mathbf{x}_0}\\right)_\\mathrm{pcr}=\\mathbf{P}_R(\\mathbf{T}_R\\mathbf{T}_R^\\mathrm{T})^{-1}\\mathbf{T}_R\\mathbf{J}_e\n\\tag{10}\\]\n\n\n\nCode\nsolver='pcr'\ndJedx0, dxeopt=enasa(solver=solver)\ndJdx0_dict[solver] = dJedx0\ndxopt_dict[solver] = dxeopt\nJeest_dict[solver] = enasa.estimate()\nres_nl, res_tl = check_djdx(dJedx0,dxeopt,vt,title=solver)\nresnl_dict[solver] = res_nl \nrestl_dict[solver] = res_tl\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nridge regression \\[\n\\left(\\frac{\\partial J_\\mathrm{e}}{\\partial \\mathbf{x}_0}\\right)_\\mathrm{ridge}=(\\mathbf{X}_0\\mathbf{X}_0^\\mathrm{T}+\\mu\\mathbf{I})^{-1}\\mathbf{X}_0\\mathbf{J}_\\mathrm{e},\n\\tag{11}\\] where \\(\\mu\\) is a hyper parameter.\n\n\n\nCode\nsolver='ridge'\ndJedx0, dxeopt=enasa(solver=solver)\ndJdx0_dict[solver] = dJedx0\ndxopt_dict[solver] = dxeopt\nJeest_dict[solver] = enasa.estimate()\nres_nl, res_tl = check_djdx(dJedx0,dxeopt,vt,title=solver)\nresnl_dict[solver] = res_nl \nrestl_dict[solver] = res_tl\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npartial least square (PLS) regression\nThe target vector is also projected onto a latent space spanned by the principal components. \\[\n\\left(\\frac{\\partial J_\\mathrm{e}}{\\partial \\mathbf{x}_0}\\right)_\\mathrm{pls}=\\mathbf{W}(\\mathbf{P}^\\mathrm{T}\\mathbf{W})^{-1}\\mathbf{d}\n\\tag{12}\\] where \\(\\mathbf{W}=[\\mathbf{w}_1,\\cdots,\\mathbf{w}_R]\\), \\(\\mathbf{P}=[\\mathbf{p}_1,\\cdots,\\mathbf{p}_R]\\), and \\(\\mathbf{d}=[d_1,\\cdots,d_R]^\\mathrm{T}\\) are determined iteratively, \\[\n\\mathbf{w}_r=\\frac{\\mathbf{X}_0^{(r)}\\mathbf{J}^{(r)}_\\mathrm{e}}{\\|\\mathbf{X}_0^{(r)}\\mathbf{J}^{(r)}_\\mathrm{e}\\|}\n, \\quad \\mathbf{t}_r=(\\mathbf{X}_0^{(r)})^\\mathrm{T}\\mathbf{w}_r\n, \\quad \\mathbf{p}_r=\\frac{\\mathbf{X}_0^{(r)}\\mathbf{t}_r}{\\|\\mathbf{t}_r\\|}\n, \\quad d_r=\\frac{\\mathbf{t}_r^\\mathrm{T}\\mathbf{J}^\\mathrm{(r)}_\\mathrm{e}}{\\|\\mathbf{t}_r\\|}\n\\]\n\\(\\mathbf{X}_0^{(r)}, \\mathbf{J}_\\mathrm{e}^{(r)}\\) are obtained from deflation.\n\n\n\nCode\nsolver='pls'\ndJedx0, dxeopt=enasa(solver=solver)\ndJdx0_dict[solver] = dJedx0\ndxopt_dict[solver] = dxeopt\nJeest_dict[solver] = enasa.estimate()\nres_nl, res_tl = check_djdx(dJedx0,dxeopt,vt,title=solver)\nresnl_dict[solver] = res_nl \nrestl_dict[solver] = res_tl"
  },
  {
    "objectID": "EnASA_L96.html#comparison-of-enasa-methods",
    "href": "EnASA_L96.html#comparison-of-enasa-methods",
    "title": "Comparison of adjoint sensitivity analysis and ensemble adjoint sensitivity analysis using Lorenz-96 model",
    "section": "Comparison of EnASA methods",
    "text": "Comparison of EnASA methods\n\n\nCode\nmarkers=['*','o','v','s','P','X','p']\nmarker_style=dict(markerfacecolor='none')\nfig, ax = plt.subplots()\nfor i,key in enumerate(dJdx0_dict.keys()):\n    if key=='ASA':\n        ax.plot(dJdx0_dict[key],label=key,lw=2.0)\n    else:\n        ax.plot(dJdx0_dict[key],ls='dashed',marker=markers[i],label=f'EnASA,{key}',**marker_style)\nax.legend()\nax.grid()\nax.set_title('dJ/dx0')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\nfig, ax = plt.subplots()\nfor i,key in enumerate(dxopt_dict.keys()):\n    if key=='ASA':\n        ax.plot(dxopt_dict[key],label=key,lw=2.0)\n    else:\n        ax.plot(dxopt_dict[key],ls='dashed',marker=markers[i],label=f'EnASA,{key}',**marker_style)\nax.legend()\nax.grid()\nax.set_title('dxopt')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\nfig, ax = plt.subplots()\nfor i,key in enumerate(resnl_dict.keys()):\n    ax.plot(abs(resnl_dict[key]),abs(restl_dict[key]),marker=markers[i],lw=0.0,ms=10,label=key,**marker_style)\nymin, ymax = ax.get_ylim()\nline = np.linspace(ymin,ymax,100)\nax.plot(line,line,color='k',zorder=0)\nax.set_xlabel(r'NLM: $|J(M(\\mathbf{x}_0+\\delta\\mathbf{x}_0^\\mathrm{opt}))-J(\\mathbf{x}_T)|/J(\\mathbf{x}_T)$')\nax.set_ylabel(r'TLM: $|J(\\mathbf{x}_T+\\mathbf{M}\\delta\\mathbf{x}_0^\\mathrm{opt})-J(\\mathbf{x}_T)|/J(\\mathbf{x}_T)$')\nax.set_title(r'$|\\delta J|/J$')\nax.legend()\nax.grid()\nax.set_aspect(1.0)\nplt.show()\n\n\n\n\n\n\n\n\n\n\\[\n\\hat{\\mathbf{J}_\\mathrm{e}}=\\mathbf{X}_0^\\mathrm{T}\\frac{\\partial J_\\mathrm{e}}{\\partial \\mathbf{x}_0} + \\boldsymbol{\\varepsilon}\n\\]\n\n\nCode\nfig, axs = plt.subplots(ncols=2,constrained_layout=True)\ncmap=plt.get_cmap('tab10')\nfor i,key in enumerate(Jeest_dict.keys()):\n    #fig, ax = plt.subplots()\n    if key=='diag':\n        axs[0].plot(Je,Jeest_dict[key],lw=0.0,marker=markers[i+1],c=cmap(i+1),label=key,**marker_style)\n    else:\n        axs[1].plot(Je,Jeest_dict[key],lw=0.0,marker=markers[i+1],c=cmap(i+1),label=key,**marker_style)\nfor ax in axs:\n    ymin, ymax = ax.get_ylim()\n    line = np.linspace(ymin,ymax,100)\n    ax.plot(line,line,color='k',zorder=0)\n    ax.set_xlabel('observed')\n    ax.set_ylabel('estimated')\n    ax.set_title('Je')\n    ax.legend()\n    #ax.set_title(key)\n    ax.grid()\n    ax.set_aspect(1.0)\nplt.show()"
  },
  {
    "objectID": "EnASA_L96.html#lead-time",
    "href": "EnASA_L96.html#lead-time",
    "title": "Comparison of adjoint sensitivity analysis and ensemble adjoint sensitivity analysis using Lorenz-96 model",
    "section": "Lead time",
    "text": "Lead time\n\n\nCode\nenasa_list = ['minnorm','diag','pcr','ridge','pls']\nnenasa = len(enasa_list)\nvtlist = [24,48,72,96]\ndJdx0_dict = dict()\ndxopt_dict = dict()\nresnl_dict = dict()\nrestl_dict = dict()\nfor vt in vtlist:\n    dJdx0,dxopt = asa(vt)\n    res_nl, res_tl = check_djdx(dJdx0,dxopt,vt,plot=False)\n    dJdx0_dict[vt] = dJdx0\n    dxopt_dict[vt] = dxopt\n    resnl_dict[f\"ASA,{vt}h\"] = res_nl\n    restl_dict[f\"ASA,{vt}h\"] = res_tl\n    fig, ax = plt.subplots()\n    ax.plot(dJdx0_dict[vt],label='ASA')\n    fig2, ax2 = plt.subplots()\n    ax2.plot(dxopt_dict[vt],label='ASA')\n    dJedx0_dict = dict()\n    dxeopt_dict = dict()\n    Jeest_dict=dict()\n    Je, X0 = generate_prtb(vt,xb,xe)\n    enasa = EnASA(vt, X0, Je)\n    i = 1\n    for etype in enasa_list:\n        dJedx0, dxeopt = enasa(solver=etype)\n        dJedx0_dict[etype] = dJedx0\n        Jeest_dict[etype] = enasa.estimate()\n        dxeopt_dict[etype]=dxeopt\n        res_nl, res_tl = check_djdx(dJedx0,dxeopt,vt,plot=False)\n        resnl_dict[f\"{etype},{vt}h\"] = res_nl\n        restl_dict[f\"{etype},{vt}h\"] = res_tl\n        ax.plot(dJedx0,ls='dashed',marker=markers[i],label=f'EnASA,{etype}',**marker_style)\n        ax2.plot(dxeopt,ls='dashed',marker=markers[i],label=f'EnASA,{etype}',**marker_style)\n        i+=1\n    ax.legend()\n    ax.grid()\n    ax.set_title(f'dJ/dx0, vt={vt}h')\n\n    ax2.legend()\n    ax2.grid()\n    ax2.set_title(f'dxopt, vt={vt}h')\n    plt.show()\n\n    fig, axs = plt.subplots(ncols=2,constrained_layout=True)\n    for i,key in enumerate(Jeest_dict.keys()):\n        if key=='diag':\n            axs[0].plot(Je,Jeest_dict[key],lw=0.0,marker=markers[i+1],c=cmap(i+1),label=key,**marker_style)\n        else:\n            axs[1].plot(Je,Jeest_dict[key],lw=0.0,marker=markers[i+1],c=cmap(i+1),label=key,**marker_style)\n    for ax in axs:\n        ymin, ymax = ax.get_ylim()\n        line = np.linspace(ymin,ymax,100)\n        ax.plot(line,line,color='k',zorder=0)\n        ax.set_xlabel('observed')\n        ax.set_ylabel('estimated')\n        ax.set_title(f'Je, vt={vt}h')\n        ax.legend()\n        #ax.set_title(key)\n        ax.grid()\n        ax.set_aspect(1.0)\n    plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nfig, ax = plt.subplots()\ncmap2 = plt.get_cmap('tab20')\nfor i,key in enumerate(resnl_dict.keys()):\n    icol = i // (nenasa+1)\n    imrk = i - icol*(nenasa+1)\n    if imrk==0:\n        marker_style.update(markerfacecolor=cmap2(2*icol+1))\n    else:\n        marker_style.update(markerfacecolor='none')\n    ax.plot(abs(resnl_dict[key]),abs(restl_dict[key]),marker=markers[imrk],c=cmap(icol),lw=0.0,ms=10,label=key,**marker_style)\nymin, ymax = ax.get_ylim()\nline = np.linspace(ymin,ymax,100)\nax.plot(line,line,color='k',zorder=0)\nax.set_xlabel(r'NLM: $|J(M(\\mathbf{x}_0+\\delta\\mathbf{x}_0^\\mathrm{opt}))-J(\\mathbf{x}_T)|/J(\\mathbf{x}_T)$')\nax.set_ylabel(r'TLM: $|J(\\mathbf{x}_T+\\mathbf{M}\\delta\\mathbf{x}_0^\\mathrm{opt})-J(\\mathbf{x}_T)|/J(\\mathbf{x}_T)$')\nax.set_title(r'$|\\delta J|/J$'+f', Nens={nens}')\nax.legend(ncol=2,loc='upper left',bbox_to_anchor=(1.01,1.0))\nax.grid()\nax.set_aspect(1.0)\nplt.show()"
  },
  {
    "objectID": "EnASA_L96.html#ensemble-size",
    "href": "EnASA_L96.html#ensemble-size",
    "title": "Comparison of adjoint sensitivity analysis and ensemble adjoint sensitivity analysis using Lorenz-96 model",
    "section": "Ensemble size",
    "text": "Ensemble size\n\n\nCode\nvt = 24\nnenslist = [5, 10, 20, 40, 80, 160]\nresnle_dict=dict()\nrestle_dict=dict()\nfor nens in nenslist:\n    fig, ax = plt.subplots()\n    ax.plot(dJdx0_dict[vt],label='ASA')\n    fig2, ax2 = plt.subplots()\n    ax2.plot(dxopt_dict[vt],label='ASA')\n    dJedx0_dict=dict()\n    Jeest_dict=dict()\n    dxeopt_dict=dict()\n    xe = create_ens(nens)\n    Je, X0 = generate_prtb(vt,xb,xe)\n    enasa = EnASA(vt, X0, Je)\n    enasa_list_tmp = enasa_list.copy()\n    if nens &gt; nx:\n        enasa_list_tmp.append('minvar')\n    i = 1\n    for etype in enasa_list_tmp:\n        dJedx0, dxeopt = enasa(solver=etype)\n        dJedx0_dict[etype] = dJedx0\n        Jeest_dict[etype] = enasa.estimate()\n        dxeopt_dict[etype]=dxeopt\n        res_nl, res_tl = check_djdx(dJedx0, dxeopt, vt, plot=False)\n        resnle_dict[f'{etype},{nens}'] = res_nl\n        restle_dict[f'{etype},{nens}'] = res_tl\n        ax.plot(dJedx0,ls='dashed',marker=markers[i],label=f'EnASA,{etype}',**marker_style)\n        ax2.plot(dxeopt,ls='dashed',marker=markers[i],label=f'EnASA,{etype}',**marker_style)\n        i+=1\n    ax.legend()\n    ax.grid()\n    ax.set_title(f'dJ/dx0, vt={vt}h, Nens={nens}')\n\n    ax2.legend()\n    ax2.grid()\n    ax2.set_title(f'dxopt, vt={vt}h, Nens={nens}')\n    plt.show()\n\n    fig, axs = plt.subplots(ncols=2,constrained_layout=True)\n    for i,key in enumerate(Jeest_dict.keys()):\n        if key=='diag':\n            axs[0].plot(Je,Jeest_dict[key],lw=0.0,marker=markers[i],c=cmap(i+1),label=key,**marker_style)\n        else:\n            axs[1].plot(Je,Jeest_dict[key],lw=0.0,marker=markers[i],c=cmap(i+1),label=key,**marker_style)\n    for ax in axs:\n        ymin, ymax = ax.get_ylim()\n        line = np.linspace(ymin,ymax,100)\n        ax.plot(line,line,color='k',zorder=0)\n        ax.set_xlabel('observed')\n        ax.set_ylabel('estimated')\n        ax.set_title(f'Je, vt={vt}h, Nens={nens}')\n        ax.legend()\n        #ax.set_title(key)\n        ax.grid()\n        ax.set_aspect(1.0)\n    plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nimport re\nfig, ax = plt.subplots()\ncmap2 = plt.get_cmap('tab20')\nkey = f'ASA,{vt}h'\nax.plot(abs(resnl_dict[key]),abs(restl_dict[key]),marker=markers[0],c='k',lw=0.0,ms=10,label=key)\nfor i,key in enumerate(resnle_dict.keys()):\n    m = re.search(',',key)\n    j = m.start()\n    etype = key[:j]\n    cens = key[j+1:]\n    icol = nenslist.index(int(cens))\n    if etype == 'minvar':\n        imrk = -1\n    else:\n        imrk = enasa_list.index(etype) + 1\n    marker_style.update(markerfacecolor='none')\n    ax.plot(abs(resnle_dict[key]),abs(restle_dict[key]),marker=markers[imrk],c=cmap(icol),lw=0.0,ms=10,label=key,**marker_style)\nymin, ymax = ax.get_ylim()\nline = np.linspace(ymin,ymax,100)\nax.plot(line,line,color='k',zorder=0)\nax.set_xlabel(r'NLM: $|J(M(\\mathbf{x}_0+\\delta\\mathbf{x}_0^\\mathrm{opt}))-J(\\mathbf{x}_T)|/J(\\mathbf{x}_T)$')\nax.set_ylabel(r'TLM: $|J(\\mathbf{x}_T+\\mathbf{M}\\delta\\mathbf{x}_0^\\mathrm{opt})-J(\\mathbf{x}_T)|/J(\\mathbf{x}_T)$')\nax.set_title(r'$|\\delta J|/J$'+f', vt={vt}h')\nax.legend(ncol=2,loc='upper left',bbox_to_anchor=(1.01,1.0))\nax.grid()\nax.set_aspect(1.0)\nplt.show()"
  },
  {
    "objectID": "EnASA_L96.html#hyper-parameters",
    "href": "EnASA_L96.html#hyper-parameters",
    "title": "Comparison of adjoint sensitivity analysis and ensemble adjoint sensitivity analysis using Lorenz-96 model",
    "section": "Hyper parameters",
    "text": "Hyper parameters\n\nridge regression\n\n\nCode\nnens = 20\nvt = 72\nmulist = [0.001,0.01,0.1,1.0]\ndJedx0_dict=dict()\nJeest_dict=dict()\ndxeopt_dict=dict()\nresnle_dict=dict()\nrestle_dict=dict()\nxe = create_ens(nens)\nJe, X0 = generate_prtb(vt,xb,xe)\nenasa = EnASA(vt, X0, Je)\nfor mu in mulist:\n    dJedx0, dxeopt = enasa(solver='ridge',mu=mu)\n    dJedx0_dict[mu] = dJedx0\n    Jeest_dict[mu] = enasa.estimate()\n    dxeopt_dict[mu] = dxeopt\n    res_nl, res_tl = check_djdx(dJedx0, dxeopt, vt, plot=False)\n    resnle_dict[mu] = res_nl\n    restle_dict[mu] = res_tl\n\n\n\n\nCode\nimrk = enasa_list.index('ridge') + 1\n\nfig, ax = plt.subplots()\nax.plot(dJdx0_dict[vt],label='ASA')\nfor i,key in enumerate(dJedx0_dict.keys()):\n    ax.plot(dJedx0_dict[key],ls='dashed',marker=markers[imrk],label=r'$\\mu$='+f'{key}',**marker_style)\nax.legend()\nax.grid()\nax.set_title(f'dJ/dx0, vt={vt}h, Nens={nens}')\nplt.show()\n\nfig, ax = plt.subplots()\nax.plot(dxopt_dict[vt],label='ASA')\nfor i,key in enumerate(dxeopt_dict.keys()):\n    ax.plot(dxeopt_dict[key],ls='dashed',marker=markers[imrk],label=r'$\\mu$='+f'{key}',**marker_style)\nax.legend()\nax.grid()\nax.set_title(f'dxopt, vt={vt}h, Nens={nens}')\nplt.show()\n\nfig, ax = plt.subplots()\nfor i,key in enumerate(Jeest_dict.keys()):\n    ax.plot(Je,Jeest_dict[key],lw=0.0,marker=markers[imrk],c=cmap(i+1),label=r'$\\mu$='+f'{key}',**marker_style)\nymin, ymax = ax.get_ylim()\nline = np.linspace(ymin,ymax,100)\nax.plot(line,line,color='k',zorder=0)\nax.set_xlabel('observed')\nax.set_ylabel('estimated')\nax.set_title(f'Je, vt={vt}h, Nens={nens}')\nax.legend()\n#ax.set_title(key)\nax.grid()\nax.set_aspect(1.0)\nplt.show()\n\nfig, ax = plt.subplots()\ncmap2 = plt.get_cmap('tab20')\nkey = f'ASA,{vt}h'\nax.plot(abs(resnl_dict[key]),abs(restl_dict[key]),marker=markers[0],c='k',lw=0.0,ms=10,label=key)\nfor i,key in enumerate(resnle_dict.keys()):\n    icol = i\n    imrk = enasa_list.index('ridge') + 1\n    marker_style.update(markerfacecolor='none')\n    ax.plot(abs(resnle_dict[key]),abs(restle_dict[key]),marker=markers[imrk],c=cmap(icol),lw=0.0,ms=10,label=r'$\\mu$='+f'{key}',**marker_style)\nymin, ymax = ax.get_ylim()\nline = np.linspace(ymin,ymax,100)\nax.plot(line,line,color='k',zorder=0)\nax.set_xlabel(r'NLM: $|J(M(\\mathbf{x}_0+\\delta\\mathbf{x}_0^\\mathrm{opt}))-J(\\mathbf{x}_T)|/J(\\mathbf{x}_T)$')\nax.set_ylabel(r'TLM: $|J(\\mathbf{x}_T+\\mathbf{M}\\delta\\mathbf{x}_0^\\mathrm{opt})-J(\\mathbf{x}_T)|/J(\\mathbf{x}_T)$')\nax.set_title(r'$|\\delta J|/J$'+f', vt={vt}h, Nens={nens}')\nax.legend(ncol=2,loc='upper left',bbox_to_anchor=(1.01,1.0))\nax.grid()\nax.set_aspect(1.0)\nplt.show()"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "pyesa/about.html",
    "href": "pyesa/about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  }
]